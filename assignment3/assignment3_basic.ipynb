{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment3_basic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPM3XOpnx6qf",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 3 option 2: ConvNet\n",
        "In this assignment you will train a ConvNet to predict the language of a\n",
        "surname from its spelling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToNoisdGjRuM",
        "colab_type": "code",
        "outputId": "81a954d0-42a5-4186-f7a5-623c65bb6e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/f9/0626bbdb322e3a078d968e87e3b01341e7890544de891d0cb613641220e6/ipython-autotime-0.1.tar.bz2\n",
            "Building wheels for collected packages: ipython-autotime\n",
            "  Building wheel for ipython-autotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipython-autotime: filename=ipython_autotime-0.1-cp36-none-any.whl size=1832 sha256=804535c85273270f7dab7a950b92a59f3812394b516c77dd54a25b6b2cfbc9ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/df/81/2db1e54bc91002cec40334629bc39cfa86dff540b304ebcd6e\n",
            "Successfully built ipython-autotime\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33B0OGvt1W8_",
        "colab_type": "code",
        "outputId": "3b5916f6-32e7-45f7-c50f-f333d28630f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "import random\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import sparse\n",
        "from collections import Counter\n",
        "from operator import itemgetter\n",
        "from random import sample "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 321 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z15WVr0ZypAu",
        "colab_type": "text"
      },
      "source": [
        "# Component 1: Preparing Data\n",
        "Read in the training data, determine the maximum\n",
        "length of all the names in the dataset, determine the number of unique\n",
        "characters in the text and set up mapping functions - one mapping\n",
        "each character to a unique index and another mapping each index to a character.\n",
        "\n",
        "## 0.1 Read in the data and get it ready\n",
        "read in acsii_names.txt\n",
        "put all names and ther labels un a call array all_names and a vector y \n",
        "convert all uppercase letters to lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8si6my0zxmUI",
        "colab_type": "code",
        "outputId": "d96a8d7e-af12-4266-fa8f-abdd1e8464bc",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# upload txt file to colab: https://buomsoo-kim.github.io/colab/2018/04/15/Colab-Importing-CSV-and-JSON-files-in-Google-Colab.md/\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-801d8871-ce2c-490c-9754-81a84b9ce427\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-801d8871-ce2c-490c-9754-81a84b9ce427\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 32.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqRt3dTiHIVD",
        "colab_type": "code",
        "outputId": "13b45ecb-928d-47fb-a8c7-f1c54905e374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "# preporocess data\n",
        "names_train = []\n",
        "names_val = []\n",
        "labels_train = []\n",
        "labels_val = []\n",
        "\n",
        "name_data = \"ascii_names.txt\"\n",
        "validation_data = \"Validation_Inds.txt\"\n",
        "names = uploaded[name_data].decode(\"utf-8\").split(\"\\n\")\n",
        "validation_idx = uploaded[validation_data].decode(\"utf-8\").split()\n",
        "names = list(filter(lambda x: x != \"\", names))\n",
        "for i in range(len(names)):\n",
        "  line = names[i].split(\",\")[0].rsplit(' ', 1)\n",
        "  if len(line)>1 and line[1] != '':\n",
        "    if str(i+1) in validation_idx: \n",
        "      names_val.append(line[0].lower())\n",
        "      labels_val.append(int(line[1]))\n",
        "    else:\n",
        "      names_train.append(line[0].lower())\n",
        "      labels_train.append(int(line[1]))\n",
        "\n",
        "print(len(names_val), len(names_train), len(labels_val), len(labels_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1c39ea586f8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mname_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ascii_names.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Validation_Inds.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mvalidation_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'ascii_names.txt'"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "time: 15.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuF8uLtILOaR",
        "colab_type": "code",
        "outputId": "087fed09-080e-4827-fcef-2384d3835610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "C = sorted(set([i for ele in names_train for i in ele])) # set of unique characters in names\n",
        "d = len(C) # number of unique characters in names\n",
        "n_len =  len(max(names_train, key=len)) # size of longest name in names\n",
        "K = len(set(labels_train)) # number of classes\n",
        "char_to_ind =  { val : id for id,val in enumerate(C) } # dict with char and index in set C"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ec5d25162d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames_train\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mele\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# set of unique characters in names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# number of unique characters in names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mn_len\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# size of longest name in names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# number of classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchar_to_ind\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m{\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m}\u001b[0m \u001b[0;31m# dict with char and index in set C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "time: 10.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK_HSq6Fg0So",
        "colab_type": "code",
        "outputId": "6c205333-4447-473d-e930-a6984b39a458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def createOneHot_name(_name, _char_to_ind, _n_len, _d):\n",
        "  values =  [_char_to_ind[val] for val in list(_name)]\n",
        "  one_hot = np.eye(_d)[values].copy()\n",
        "  one_hot.resize((_n_len, _d),  refcheck=False)\n",
        "  return one_hot.T \n",
        "createOneHot_name('abc', char_to_ind, 4, 6).flatten('F')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "stream",
          "text": [
            "time: 4.83 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4yzFcpj0oaE",
        "colab_type": "code",
        "outputId": "e043536e-2dd4-4629-ae5a-405851b18be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# create X as one hot encoding for names: columns represent names, rows the vectorized information\n",
        "def createOneHot_X(names):\n",
        "  X = np.zeros((d*n_len, len(names)))\n",
        "  for id,name in enumerate(names):\n",
        "    X[:,id] = createOneHot_name(name, char_to_ind, n_len, d).flatten('F')\n",
        "  return X\n",
        "\n",
        "print(createOneHot_X(names_train).shape, len(names_train))\n",
        "print(createOneHot_X(names_val).shape, len(names_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(532, 19798) 19798\n",
            "(532, 252) 252\n",
            "time: 374 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8rWIOTvzYPt",
        "colab_type": "code",
        "outputId": "a90040fb-2759-4a28-ea02-09fab49e005f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# create one hot encoding for labels --> each column corresponds to one name\n",
        "def createOneHot_Y(labels):\n",
        "  onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
        "  Y = onehot_encoder.fit_transform(np.array(labels).reshape(-1,1)).astype(int).T\n",
        "  return Y\n",
        "print(createOneHot_Y(labels_train).shape)\n",
        "print(createOneHot_Y(labels_val).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18, 19798)\n",
            "(18, 252)\n",
            "time: 16.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep2ITSlj-rzY",
        "colab_type": "code",
        "outputId": "11cd6010-138f-40a0-ba82-020aa571d46d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# plot all graphs\n",
        "def plotResults(costs_train, accs_train, costs_validate, accs_validate, safeto, save=False):\n",
        "    # plotting costs\n",
        "    plt.plot(costs_train, label = \"training\")\n",
        "    plt.plot(costs_validate, label = \"validation\")\n",
        "    plt.xlabel('saving steps')\n",
        "    plt.ylabel('cost')\n",
        "    plt.suptitle('Cost')\n",
        "    plt.legend()\n",
        "    if save:\n",
        "        plt.savefig('Result_Pics/'+safeto+'cost.png')\n",
        "    plt.show()  \n",
        "    \n",
        "    # plotting accuracy\n",
        "    plt.plot(accs_train, label = 'training')\n",
        "    plt.plot(accs_validate, label = 'validation')\n",
        "    plt.xlabel('saving steps')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.suptitle('Accuracy')\n",
        "    plt.legend()\n",
        "    if save:\n",
        "        plt.savefig('Result_Pics/'+safeto+'acc.png')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 9.68 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHUI13prORyp",
        "colab_type": "text"
      },
      "source": [
        "# 2 Convolutional Network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb2_kuwnguYT",
        "colab_type": "code",
        "outputId": "c690e1f0-22f4-4a56-e8f5-dbf3f8779195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# object for parameters \n",
        "random.seed( 30 )\n",
        "\n",
        "class ConvNet():\n",
        "  def __init__(self, n_classes, eta, rho, ns, ks, d, n_len, K, L):\n",
        "    self.L = L # number of conv layers\n",
        "    self.n = ns # filters applied at layer  []\n",
        "    self.k = ks # the width of the filters applied at layer []\n",
        "    self.n_len = n_len\n",
        "    self.d = d\n",
        "    self.F = {}\n",
        "    self.eta = eta\n",
        "    self.rho = rho\n",
        "    self.M_filter = {}\n",
        "    self.len_f = [] # lens used for calculation MF matrix for each layer []\n",
        "    self.K = K\n",
        "    self.confusion = []\n",
        "\n",
        "    self.len_f.append(n_len)\n",
        "    for i in range(L):\n",
        "      # n len f\n",
        "      n_len_new =  self.len_f[-1]-ks[i]+1\n",
        "      self.len_f.append(n_len_new)\n",
        "      # filters\n",
        "      if i == 0:\n",
        "        self.F[i] = np.zeros((self.d, self.k[i], self.n[i]) ) \n",
        "      else:\n",
        "        self.F[i] = np.zeros((self.n[i-1], self.k[i], self.n[i]) )\n",
        "    self.W = np.zeros((n_classes, self.len_f[-1] * self.n[-1]))  # K\u0002n2\u0003nlen2\n",
        "\n",
        "  def init(self,mu, sigma):\n",
        "    # init filters\n",
        "    for i in range(self.L):\n",
        "        self.F[i] = np.random.normal(mu, sigma, self.F[i].shape ) \n",
        "    # init W\n",
        "    self.W = np.random.normal(mu, sigma, self.W.shape) \n",
        "\n",
        "  def makeMFMatrix(self, F, n_len):\n",
        "    (d, k, nf) = F.shape\n",
        "    M_filter = np.zeros(((n_len -k+1)*nf, n_len*d))\n",
        "    Vec_filter = F.reshape((d*k, nf), order = 'F').T\n",
        "    #print (F.shape, Vec_filter.shape, M_filter.shape)\n",
        "\n",
        "    for i in range(n_len - k + 1):\n",
        "      row_start = i * nf\n",
        "      row_end = (i + 1) * nf\n",
        "      col_start = d * i\n",
        "      col_end = d * i + d * k      \n",
        "      M_filter [row_start:row_end,col_start:col_end] = Vec_filter\n",
        "    \n",
        "    return M_filter\n",
        "\n",
        "  def makeMXMatrix(self, x_input, d, k, nf, stride = 1):    #d,k,nf = size(F)\n",
        "    n_len = int(len(x_input)/d)\n",
        "    M_input = np.zeros((nf*(n_len -k+1),nf*d*k))\n",
        "    x_input = x_input.reshape((d, n_len), order='F') # todo: try to get a version without all the shaping\n",
        "    \n",
        "    for i in range((n_len -k+1)):\n",
        "      row_start = i * nf   \n",
        "      vec =  (x_input[:, i:k+i].reshape((d*k, 1), order='F')).T \n",
        "      #vec = x_input[i*d*stride: k*d*stride+i*d*stride]\n",
        "      for j in range(nf):     \n",
        "        M_input [row_start+j, j*d*k: (j+1)*d*k] = vec\n",
        "  \n",
        "    return M_input\n",
        "\n",
        "  ''' np.kron is very slow in this loop. Do not use it! Use makeMXMatrix instead '''\n",
        "  def makeMXMatrixKron(self, x_input, d, k, nf, stride = 1):    #F.shape = d x k x nf  , d = 28, k&nf to decide\n",
        "    n_len = int(len(x_input)/d)               \t    # X.shape = d x n_len\n",
        "    M_input = np.zeros((nf*(n_len -k+1),nf*d*k))    # size of MX\n",
        "    vec = np.zeros(((n_len -k+1),d*k))              # one vector square\n",
        "\n",
        "    x_input = x_input.reshape((d, n_len), order='F') # todo: try to get a version without all the shaping\n",
        "    print(x_input.shape, d, k, nf, n_len, (n_len -k+1), M_input.shape )\n",
        "\n",
        "    for i in range((n_len -k+1)):\n",
        "      vec[i] =  (x_input[:, i:k+i].reshape((d*k, 1), order='F')).T \n",
        "      #vec[i]= x_input[i*d*stride: k*d*stride+i*d*stride]\n",
        "      if i == 0:\n",
        "        M_input =  np.kron(np.eye(nf),vec[i])\n",
        "      else:\n",
        "        M_input = np.vstack((M_input, np.kron(np.eye(nf),vec[i])))\n",
        "  \n",
        "    return M_input\n",
        "\n",
        "  def makeMXMatrixVec(self, x_input, d, k):    #d,k,nf = size(F)\n",
        "    n_len = int(len(x_input)/d)\n",
        "    vec = np.zeros(((n_len -k+1),d*k))\n",
        "    x_input = x_input.reshape((d, n_len), order='F') # todo: try to get a version without all the shaping\n",
        "    \n",
        "    for i in range((n_len -k+1)):\n",
        "      vec[i] =  (x_input[:, i:k+i].reshape((d*k, 1), order='F')).T \n",
        "  \n",
        "    return vec\n",
        "\n",
        "  def softmax(self, scores):\n",
        "   # return np.exp(scores) / np.sum(np.exp(scores), axis=0)\n",
        "    f = np.exp(scores - np.max(scores))  # avoiding nan for large numbers\n",
        "    return f / f.sum(axis=0)\n",
        "\n",
        "  def evaluateClassifier(self, X_batch, MFs, W): # forward pass\n",
        "    X_batches = [X_batch]\n",
        "    for i in range(len(MFs)):\n",
        "      new_X_batch = np.maximum(np.dot(MFs[i],X_batches[i]), 0)\n",
        "      X_batches.append(new_X_batch)\n",
        "\n",
        "    # fully connected\n",
        "    S_batch = np.dot(W ,X_batches[-1])\n",
        "    # Apply the SoftMax operator to each column\n",
        "    P_batch = self.softmax(S_batch)\n",
        "\n",
        "    return X_batches[1], X_batches[2], P_batch\n",
        "\n",
        "  def crossEntropyLoss(self, X, Y, MFs, W):\n",
        "    _, _, P = self.evaluateClassifier(X, MFs, W)\n",
        "    Y = np.reshape(Y, (P.shape))\n",
        "    loss = -(np.multiply(Y, np.log(P)))  # check this:  - np.sum(Y*np.log(P)), removed  np.sum\n",
        "    return loss\n",
        "\n",
        "  def cost(self, X, Y, MFs, W):\n",
        "    J = np.sum(self.crossEntropyLoss(X, Y, MFs, W)) / X.shape[1]\n",
        "    return J\n",
        "\n",
        "  def computeAccuracy(self, X, labels, MFs, W):\n",
        "    _, _, P = self.evaluateClassifier(X, MFs, W)\n",
        "    pred = np.argmax(P, axis=0)\n",
        "    pred = [x + 1 for x in pred]\n",
        "    #print(pred)\n",
        "    acc = np.count_nonzero(np.array(pred) == np.array(labels)) / X[1].size\n",
        "    return acc\n",
        "\n",
        "  def passBackward(self, X_batch, X_batch1, X_batch2, P_batch, Y_batch, MFs, MX_prec):\n",
        "    # assume forward pass / evaluate classifier is done before\n",
        "\n",
        "    grad_W = np.zeros(self.W.shape)\n",
        "    grad_F = []\n",
        "\n",
        "    for i in range(len(self.F)):\n",
        "      grad_F.append(np.zeros(self.F[i].shape))\n",
        "    \n",
        "    G_batch = - (Y_batch - P_batch)\n",
        "\n",
        "    grad_W = np.dot(G_batch, X_batch2.T) / X_batch2.shape[1]\n",
        "\n",
        "    G_batch = np.dot(self.W.T, G_batch)\n",
        "    G_batch = np.multiply(G_batch, np.where(X_batch2 >0, 1,0))\n",
        "\n",
        "    for j in range(X_batch1.shape[1]):\n",
        "      gj = G_batch[:,j]\n",
        "      xj = X_batch1[:,j]\n",
        "      #M_inputj = self.makeMXMatrix(xj, self.n[0], self.k[1], self.n[1] ) # use improvement 2\n",
        "      #v2 = np.dot(gj.T, M_inputj)\n",
        "      # improvement 2\n",
        "      M_inputj_vec = self.makeMXMatrixVec(xj, self.n[0], self.k[1] ) # vec from eq 21\n",
        "      len2 = int( gj.shape[0] / self.n[1]) # first dim of g_new\n",
        "      g_efficient = gj.reshape(len2, self.n[1])   \n",
        "      v2 = np.dot(M_inputj_vec.T, g_efficient) \n",
        "      grad_F[1] += v2.reshape(grad_F[1].shape, order='F') / X_batch1.shape[1]\n",
        "\n",
        "    G_batch = np.dot(MFs[1].T, G_batch)\n",
        "    G_batch = np.multiply(G_batch, np.where(X_batch1 >0,1,0))\n",
        "\n",
        "    for j in range(X_batch.shape[1]):\n",
        "      gj = G_batch[:,j]\n",
        "      xj = X_batch[:,j]\n",
        "      #M_inputj = self.makeMXMatrix(xj, self.d, self.k[0], self.n[0]) # precompute\n",
        "      # improvement 1 - not efficient\n",
        "      #M_inputj = np.asarray( MX_prec[j].todense() ) # problems with sparse explained here: https://stackoverflow.com/questions/16839840/numpy-scipy-sparse-vs-dense-multiplication\n",
        "      #v1 = np.dot(gj.T, M_inputj) # https://docs.scipy.org/doc/scipy/reference/sparse.html\n",
        "\n",
        "      # improvement 2\n",
        "      M_inputj_vec = self.makeMXMatrixVec(xj, self.d, self.k[0]) # vec from eq 21\n",
        "      len2 = int( gj.shape[0] / self.n[0]) # first dim of g_new\n",
        "      g_efficient = gj.reshape(len2, self.n[0])   \n",
        "      v1 = np.dot(M_inputj_vec.T, g_efficient) \n",
        "      grad_F[0] += v1.reshape(grad_F[0].shape, order='F') / X_batch.shape[1]\n",
        "\n",
        "    return grad_W, grad_F\n",
        "    \n",
        "  def num_grads(self, X, Y, MF, W, h):\n",
        "    '''Translation from Matlab template provided by classmate (Many thanks to Filip)'''\n",
        "    dW = np.zeros_like(W)\n",
        "    (a, b) = W.shape\n",
        "    for i in range(a):\n",
        "        for j in range(b):\n",
        "            C = []\n",
        "            \n",
        "            for m in [-1, 1]:\n",
        "                W_try = np.copy(W)\n",
        "                W_try[i, j] += m * h\n",
        "                C.append(self.cost(X, Y, MF, W_try))\n",
        "            dW[i, j] = (C[1] - C[0]) / (2 * h)\n",
        "\n",
        "    dF = [np.zeros(self.F[f].shape) for f in self.F]\n",
        "    for i in range(len(self.F)):\n",
        "        (a, b, c) = self.F[i].shape\n",
        "        for j in range(a):\n",
        "            for k in range(b):\n",
        "                for q in range(c):\n",
        "                    C = []\n",
        "\n",
        "                    for m in [-1, 1]:\n",
        "                        Fi_try = np.copy(self.F[i])\n",
        "                        Fi_try[j, k, q] += m * h\n",
        "                        MFi_try = self.makeMFMatrix(Fi_try, self.len_f[i])\n",
        "                        MF_lst = []\n",
        "                        for ii in range(len(self.F)):\n",
        "                          MF_lst.append(MFi_try if ii == i else MF[ii])\n",
        "                        C.append(self.cost(X, Y, MF_lst, W))\n",
        "                    dF[i][j, k, q] = (C[1] - C[0]) / (2 * h)\n",
        "    return dW, dF\n",
        "    \n",
        "  def computeRelativeError(self, ga ,gn ,eps):\n",
        "    return np.absolute(np.subtract(ga, gn))/np.maximum(np.add(np.absolute(ga), np.absolute(gn)), np.full(ga.shape, eps))\n",
        "  \n",
        "  def generateMiniBatches(self, n_batch, X, Y):\n",
        "    n = X[1].size\n",
        "    X_batches = []\n",
        "    Y_batches = []\n",
        "    batch_index = []\n",
        "\n",
        "    for j in range(int(n / n_batch)):\n",
        "      j_start = j * n_batch\n",
        "      j_end = (j + 1) * n_batch\n",
        "\n",
        "      X_batch = X[:, j_start:j_end]\n",
        "      Y_batch = Y[:, j_start:j_end]\n",
        "\n",
        "      X_batches.append(X_batch)\n",
        "      Y_batches.append(Y_batch)\n",
        "      batch_index.append(( j_start,j_end))\n",
        "\n",
        "    return X_batches, Y_batches, batch_index\n",
        "\n",
        "  def miniBatchGD(self, X, Y,  X_val, Y_val, labels_train, labels_val, n_batch, n_update, n_epochs, balanced):\n",
        "    costs_train = []\n",
        "    accs_train = []\n",
        "    costs_val = []\n",
        "    accs_val = []\n",
        "    MFs =[]\n",
        "    t = 0\n",
        "    #F = self.F.copy()\n",
        "    v_W = np.zeros(self.W.shape)\n",
        "    v_F = []\n",
        "   \n",
        "    # get indexes\n",
        "    index_dict = self.create_index_dict(labels_train)\n",
        "    \n",
        "    # construct M_filters\n",
        "    for i in range(len(self.F)):\n",
        "      MFs.append(self.makeMFMatrix(self.F[i], self.len_f[i]))\n",
        "      v_F.append(np.zeros(self.F[i].shape))\n",
        "\n",
        "     # precompute MX for the first layer for each batch  \n",
        "     # improvement 1 - not efficient\n",
        "    MX_prec = []\n",
        "    '''\n",
        "    for j in range(X.shape[1]):\n",
        "      xj = X[:,j]\n",
        "      MX_prec.append(sparse.csr_matrix(self.makeMXMatrix(xj, self.d, self.k[0], self.n[0])) ) \n",
        "\n",
        "    print(\"precomputing mx\")\n",
        "    MX_prec = [sparse.csr_matrix(self.makeMXMatrix(X[:,x], self.d, self.k[0], self.n[0]))  for x in range(X.shape[1])]\n",
        "    print(\"precomputing mx done \")'''\n",
        "\n",
        "    for epoch in range(n_epochs):  # iterate over epoch\n",
        "      print(\"epoch\", epoch)\n",
        "\n",
        "      if balanced:\n",
        "        # get balanced data\n",
        "        X_balanced, y_balanced = self.createBalancedDataset(X, labels_train, index_dict, self.K)\n",
        "        #Y_balanced = onehot_encoder.fit_transform(np.array(y_balanced).reshape(-1,1)).astype(int).T\n",
        "        Y_balanced = createOneHot_Y(y_balanced)\n",
        "\n",
        "        # construct batches from balanced data\n",
        "        X_batches, Y_batches, batch_index = self.generateMiniBatches(n_batch, X_balanced, Y_balanced)\n",
        "      else: \n",
        "        # construct batches from unbalanced data\n",
        "        X_batches, Y_batches, batch_index = self.generateMiniBatches(n_batch, X, Y)\n",
        "\n",
        "      # construct MF prec for batches\n",
        "      # improvement 1 - not efficient\n",
        "      '''\n",
        "      MX_prec_batches = []\n",
        "      for i in range(len(X_batches)):\n",
        "        MX_prec_batches.append(MX_prec[batch_index[i][0]:batch_index[i][1]] ) '''\n",
        "\n",
        "      #MX_prec_batches = [MX_prec[batch_index[i][0]:batch_index[i][1]] for i in range(len(X_batches))]\n",
        "      \n",
        "      for idx, X_batch in enumerate(X_batches, start=0):  # iterate over mini-batches\n",
        "        Y_batch = Y_batches[idx]\n",
        "\n",
        "         #save acc and cost every n_update step\n",
        "        if t % (n_update-1) == 0:\n",
        "          costs_train.append(self.cost(X, Y, MFs, self.W))\n",
        "          accs_train.append(self.computeAccuracy(X, labels_train, MFs, self.W))\n",
        "          costs_val.append(self.cost(X_val, Y_val, MFs, self.W))\n",
        "          accs_val.append(self.computeAccuracy(X_val, labels_val, MFs, self.W))\n",
        "        \n",
        "        # pass forward\n",
        "        X_batch1, X_batch2, P_batch = self.evaluateClassifier(X_batch, MFs, self.W)\n",
        "\n",
        "        # compute gradients / pass backwards\n",
        "\n",
        "        #MX_prec_batch = MX_prec[batch_index[idx][0]:batch_index[idx][1]]\n",
        "        grad_W, grads_F = self.passBackward(X_batch, X_batch1, X_batch2, P_batch, Y_batch, MFs,[])\n",
        "        #grad_W, grads_F = self.passBackward(X_batch, X_batch1, X_batch2, P_batch, Y_batch, MFs, MX_prec_batch) # improvement 1 - not efficient\n",
        "        \n",
        "        # momentum \n",
        "        # adjust learnung parameters \n",
        "        v_W = v_W * self.rho - self.eta * grad_W\n",
        "        v_F[0] = v_F[0] * self.rho - self.eta * grads_F[0]\n",
        "        v_F[1] = v_F[1] * self.rho - self.eta * grads_F[1]\n",
        "        self.W += v_W\n",
        "        self.F[0] += v_F[0]\n",
        "        self.F[1] += v_F[1]\n",
        "\n",
        "        # compute MFs\n",
        "        MFs = []\n",
        "        for i in range(len(self.F)):\n",
        "          MFs.append(self.makeMFMatrix(self.F[i], self.len_f[i]))\n",
        "\n",
        "        # increase t\n",
        "        t += 1\n",
        "    \n",
        "    costs_train.append(self.cost(X, Y, MFs, self.W))\n",
        "    accs_train.append(self.computeAccuracy(X, labels_train, MFs, self.W))\n",
        "    costs_val.append(self.cost(X_val, Y_val, MFs, self.W))\n",
        "    accs_val.append(self.computeAccuracy(X_val, labels_val, MFs, self.W))\n",
        "\n",
        "    #print confusion matrix for train and validate\n",
        "    self.printConfusion(X, MFs, self.W, labels_train )\n",
        "    self.printConfusion(X_val, MFs, self.W, labels_val )\n",
        " \n",
        "    return [costs_train, accs_train], [costs_val, accs_val], self.W, self.F\n",
        "\n",
        "  def printConfusion(self, X, MFs, W, y ):\n",
        "    _, _, P = self.evaluateClassifier(X, MFs, W)\n",
        "    pred = np.argmax(P, axis=0)\n",
        "    pred = [x + 1 for x in pred]\n",
        "    # how to construct confusion matrix: https://stackoverflow.com/questions/2148543/how-to-write-a-confusion-matrix-in-python\n",
        "    y_actu = pd.Series(y, name='Actual')\n",
        "    y_pred = pd.Series(pred, name='Predicted')\n",
        "    df_confusion = pd.crosstab(y_actu, y_pred,  margins=False)\n",
        "    self.confusion.append(df_confusion)\n",
        "    display(df_confusion)\n",
        "\n",
        "  def create_index_dict(self,  y_unbalanced):\n",
        "    # filter the indexes\n",
        "    indexes_for_classes = {} \n",
        "    for i, value in enumerate(y_unbalanced):\n",
        "      if value not in indexes_for_classes:\n",
        "        indexes_for_classes[value] = [i]\n",
        "        continue\n",
        "      indexes_for_classes[value].append(i)\n",
        "    return indexes_for_classes\n",
        "\n",
        "  def predict(self, X):\n",
        "    MFs_learned = []\n",
        "    for i in range(len(self.F)):\n",
        "      MFs_learned.append(conv.makeMFMatrix(self.F[i], self.len_f[i]))\n",
        "\n",
        "    X_OH = createOneHot_X(X)\n",
        "    _, _, P = conv.evaluateClassifier(X_OH, MFs_learned, self.W)\n",
        "    pred = np.argmax(P, axis=0)\n",
        "    pred = [x + 1 for x in pred]\n",
        "    \n",
        "    return pred\n",
        "\n",
        "\n",
        "  def createBalancedDataset(self, X_unbalanced, y_unbalanced, index_dict, K):\n",
        "    # using counter due to efficiency: https://stackoverflow.com/questions/2600191/how-can-i-count-the-occurrences-of-a-list-item, already sorted\n",
        "    _, min_count =  min(Counter(y_unbalanced).items(), key=itemgetter(1)) # getting min element out of it https://stackoverflow.com/questions/53046410/min-value-from-a-counter-result-in-python\n",
        "\n",
        "    X_balanced = np.zeros((X_unbalanced.shape[0], min_count*K)) \n",
        "    y_balanced = []\n",
        "    counter = 0\n",
        "    for label, indexes in index_dict.items():      # from each class indexes\n",
        "      sampled = sample(indexes,min_count ) # take a random with replacement of min size\n",
        "      for idx in sampled:\n",
        "        X_balanced[:,counter] = X_unbalanced[:,idx]\n",
        "        y_balanced.append(y_unbalanced[idx])\n",
        "        counter +=1\n",
        "\n",
        "    return X_balanced, y_balanced\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.45 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6gkpCwtfevI",
        "colab_type": "text"
      },
      "source": [
        "## 3 Checking the gradents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lcLIOMaw4JE",
        "colab_type": "code",
        "outputId": "79e12d23-c454-468c-c57b-66a2a07845a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Network definition\n",
        "# network parameters for tuning\n",
        "eta = 0.001\n",
        "rho = 0.9\n",
        "# layer specific parameters\n",
        "L = 2 # number of conv layers\n",
        "ns = [10, 10]\n",
        "ks = [5, 3]\n",
        "\n",
        "# building object and initializing\n",
        "conv = ConvNet( K, eta, rho, ns, ks, d, n_len, K, L)\n",
        "\n",
        "mu = 0\n",
        "sigma = np.sqrt(2 / d) # he init\n",
        "conv.init( mu, sigma) \n",
        "\n",
        "M_F1 = conv.makeMFMatrix(conv.F[0], n_len)\n",
        "M_F2 = conv.makeMFMatrix(conv.F[1], conv.len_f[1]) \n",
        "\n",
        "X = createOneHot_X(names_train)\n",
        "Y = createOneHot_Y(labels_train)\n",
        "\n",
        "# forward pass\n",
        "X_batch1, X_batch2, P_batch = conv.evaluateClassifier(X[:,0:10], [M_F1, M_F2], conv.W)\n",
        "# backward pass\n",
        "grad_W, grad_F = conv.passBackward(X[:,0:10], X_batch1, X_batch2, P_batch, Y[:,0:10],  [M_F1, M_F2], None)\n",
        "\n",
        "# numerical gradients\n",
        "dW, dF = conv.num_grads( X[:,0:10], Y[:,0:10], [M_F1, M_F2], conv.W, 1e-6)\n",
        "\n",
        "print(\"relative error W \", np.max(conv.computeRelativeError(dW,grad_W, 1e-6))) \n",
        "print(\"relative error F1 \", np.max(conv.computeRelativeError(dF[0],grad_F[0], 1e-6))) \n",
        "print(\"relative error F2 \", np.max(conv.computeRelativeError(dF[1],grad_F[1], 1e-6))) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "relative error W  2.0711983009322547e-05\n",
            "relative error F1  1.5559769263809966e-06\n",
            "relative error F2  2.94509993157289e-07\n",
            "time: 3.99 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZqCR6Mgfi0-",
        "colab_type": "text"
      },
      "source": [
        "## 4 Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqJXnvTOfiwJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reYOGKBkyoOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Network definition\n",
        "# network parameters for tuning\n",
        "eta = 0.005\n",
        "rho = 0.9\n",
        "# layer specific parameters\n",
        "L = 2 # number of conv layers\n",
        "ns = [20, 20]\n",
        "ks = [5, 3]\n",
        "\n",
        "# building object and initializing\n",
        "conv = ConvNet( K, eta, rho, ns, ks, d, n_len, K, L)\n",
        "\n",
        "mu = 0\n",
        "sigma = np.sqrt(2 / d) # he init\n",
        "conv.init( mu, sigma) #layer1\n",
        "\n",
        "n_batch = 100\n",
        "n_update = 500\n",
        "n_epochs = 2000\n",
        "balanced = True\n",
        "\n",
        "X = createOneHot_X(names_train)\n",
        "Y = createOneHot_Y(labels_train)\n",
        "\n",
        "X_val = createOneHot_X(names_val)\n",
        "Y_val = createOneHot_Y(labels_val)\n",
        "\n",
        "train, validate, W_learned, F_learned = conv.miniBatchGD( X, Y,  X_val, Y_val, labels_train, labels_val, n_batch, n_update, n_epochs, balanced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "876SZAwOTXTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train)\n",
        "print(validate)\n",
        "print(np.min(train[0]), np.max(train[1]))\n",
        "print(np.min(validate[0]), np.max(validate[1]))\n",
        "plotResults(train[0], train[1], validate[0], validate[1], '', save=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0NgybjLs8ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(conv.confusion)\n",
        "con = conv.confusion[1]\n",
        "\n",
        "df_conf_norm = con / con.sum(axis=1)\n",
        "print(np.diag(df_conf_norm))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT_0xqjIy06n",
        "colab_type": "text"
      },
      "source": [
        "# 5 Testing on other surnames\n",
        "List of friends provided"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GNVH-a4hzGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "friends = [ 'rather', 'pfeiffer', 'lorenzo' , 'abdelhafez', 'shunnar' , 'min' , 'fernandez', 'lusby', 'sykorova', 'kruglov', 'nguyen', 'allard' , 'charitaki' ]\n",
        "labels_friends = [7,7,10,1, 1, 12,17, 5, 3, 15, 18, 6, 8 ]\n",
        "\n",
        "pred = conv.predict(friends)\n",
        "print(pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}