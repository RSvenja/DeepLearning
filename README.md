# Deep Learning @ KTH (DD2424)

## Assignment 1: Implementing a one layer network from scratch 
- [x] Initial implementation using cross-entropy loss and L2 regularization and mini-batches
- [x] Bonus 1: Improvements to the network (Shuffling data for each epoch, longer training, using all data, decaying learning rate, Xavier initialization)
- [x] Bonus 2: SVM loss function

## Assignment 2: Implementing a two layer network from scratch 
- [x] Extending one layer network for two layers and CLR
- [x] Bonus 1: Improvements to the network (Effect of more hidden layers, data augmentation, dropout)
- [x] Bonus 2: Testing different boundaries for CLR

## Assignment 3: Convolutional Network
- [x] Implementing a ConvNet from scratch
- [x] Bonus 1: Generalizing the code to use k convolutional layers

## Assignment 4: Vanilla RNN
- [x] RNN to generate Harry Potter text
- [x] Bonus 1: Generating Twitter posts from Donald Trump




[test reference](../blob/master/assignment4/Deep_Learning.pdf)
